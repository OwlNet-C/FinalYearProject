{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### https://github.com/sjtuprog/fox-news-comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset-1.txt', encoding='utf8') as fp:\n",
    "    lst = []\n",
    "    for index, line in enumerate(fp):\n",
    "        parts = line.split(':')\n",
    "        label = int(parts[0])\n",
    "        tweet = parts[1]\n",
    "        lst.append([tweet, label])\n",
    "    dataset_1_df = pd.DataFrame(lst, columns=['tweet', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>barryswallows Merkel would never say NO\\n</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PostApocalypticHero Expect more and more women...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>californiamojo Groping people in public wasn't...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MikeSte Merkel, possible the only person in ch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scientist They know very well, no means NO! Th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0          barryswallows Merkel would never say NO\\n      1\n",
       "1  PostApocalypticHero Expect more and more women...      1\n",
       "2  californiamojo Groping people in public wasn't...      0\n",
       "3  MikeSte Merkel, possible the only person in ch...      1\n",
       "4  scientist They know very well, no means NO! Th...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_1_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://github.com/UCSM-DUE/IWG_hatespeech_public https://www.kaggle.com/kazanova/sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2_df = pd.read_csv('dataset-2.csv')\n",
    "dataset_2_df.columns = ['tweet', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...      0\n",
       "1  is upset that he can't update his Facebook by ...      0\n",
       "2  @Kenichan I dived many times for the ball. Man...      0\n",
       "3    my whole body feels itchy and like its on fire       0\n",
       "4  @nationwideclass no, it's not behaving at all....      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_2_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://www.kaggle.com/mrmorj/hate-speech-and-offensive-language-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_3_df = pd.read_csv('dataset-3.csv')\n",
    "dataset_3_df.columns = ['tweet', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@infidelpamelaLC I'm going to blame the black ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hate fat bitches</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Isa__Lopez: @D_Lo520 but you're still a fa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@kcSnowWhite7 @SamSaunders42 don't forget napp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @JihadistJoe: We Muslims have no military h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0  @infidelpamelaLC I'm going to blame the black ...      1\n",
       "1                                 I hate fat bitches      1\n",
       "2  RT @Isa__Lopez: @D_Lo520 but you're still a fa...      1\n",
       "3  @kcSnowWhite7 @SamSaunders42 don't forget napp...      1\n",
       "4  RT @JihadistJoe: We Muslims have no military h...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_3_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recalling Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(df):\n",
    "    df['tweet'].dropna(inplace=True)\n",
    "    df['tweet_temp'] = [entry.lower() for entry in df['tweet']]\n",
    "    df['tweet_temp'] = [word_tokenize(entry) for entry in df['tweet_temp']]\n",
    "\n",
    "    tag_map = defaultdict(lambda: wn.NOUN)\n",
    "    tag_map['J'] = wn.ADJ\n",
    "    tag_map['V'] = wn.VERB\n",
    "    tag_map['R'] = wn.ADV\n",
    "\n",
    "    for index, entry in enumerate(df['tweet_temp']):\n",
    "        final_words = []\n",
    "        word_Lemmatized = WordNetLemmatizer()\n",
    "\n",
    "        for word, tag in pos_tag(entry):\n",
    "            if word not in stopwords.words('english') and word.isalpha():\n",
    "                word_final = word_Lemmatized.lemmatize(word, tag_map[tag[0]])\n",
    "                final_words.append(word_final)\n",
    "        df.loc[index, 'clean_tweet'] = str(final_words)\n",
    "\n",
    "    del df['tweet_temp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing X value for Validation Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_positive_list = []\n",
    "all_negative_list = []\n",
    "n = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform(df):\n",
    "    df_positive = df[df['label'] == 0].reset_index()\n",
    "    df_negative = df[df['label'] == 1].reset_index()\n",
    "\n",
    "    clean_tweet(df_positive)\n",
    "    clean_tweet(df_negative)\n",
    "\n",
    "    df_positive.drop('index', inplace=True, axis=1)\n",
    "    df_negative.drop('index', inplace=True, axis=1)\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    positive_vec = vectorizer.fit_transform(df_positive['clean_tweet'])\n",
    "    negative_vec = vectorizer.fit_transform(df_negative['clean_tweet'])\n",
    "\n",
    "    positive_scores = zip(vectorizer.get_feature_names(), np.asarray(positive_vec.sum(axis=0)).ravel())\n",
    "    positive_sorted_scores = sorted(positive_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    negative_scores = zip(vectorizer.get_feature_names(), np.asarray(negative_vec.sum(axis=0)).ravel())\n",
    "    negative_sorted_scores = sorted(negative_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    positive_items = positive_sorted_scores[:n]\n",
    "    negative_items = negative_sorted_scores[:n]\n",
    "\n",
    "    for item in positive_items:\n",
    "        all_positive_list.append(item[0])\n",
    "    for item in negative_items:\n",
    "        all_negative_list.append(item[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying extraction on datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform(dataset_1_df)\n",
    "perform(dataset_2_df)\n",
    "perform(dataset_3_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing to lexicon file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Positive', 'Negative'], data={'Positive': all_positive_list, 'Negative': all_negative_list})\n",
    "df.to_csv('lexicon.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
